{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to start the modeling process. But first let's import all the dependencies we would need and load up the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the uneccesary warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Fix the random seed\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the numpy arrays which will be our datasets from now\n",
    "X_train, y_train = np.load(\"X_train.npy\", allow_pickle=True), np.load(\"y_train.npy\", allow_pickle=True)\n",
    "X_test, y_test = np.load(\"X_test.npy\", allow_pickle=True), np.load(\"y_test.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instantiate the Logistic Regression model and fit it to the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other imports\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import wandb\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I like to always define utility functions for training machine learning models with the code to also measure its training time and performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_pipeline(model, train_data, test_data, name):\n",
    "    # Initialize Weights and Biases\n",
    "    wandb.init(project=\"phishing-websites-detection\", name=name)\n",
    "    \n",
    "    # Segregate the datasets\n",
    "    (X_train, y_train) = train_data\n",
    "    (X_test, y_test) = test_data\n",
    "    \n",
    "    # Train the model and log all the necessary metrics\n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end = time.time() - start\n",
    "    prediction = model.predict(X_test)\n",
    "\n",
    "    wandb.log({\"accuracy\":accuracy_score(y_test, prediction)*100.0,\\\n",
    "               \"precision\": precision_recall_fscore_support(y_test, prediction, average='macro')[0],\n",
    "               \"recall\": precision_recall_fscore_support(y_test, prediction, average='macro')[1],\n",
    "               \"training_time\":end})\n",
    "    \n",
    "    print(\"Accuracy score of the Logistic Regression classifier with default hyperparameter values {0:.2f}%\"\\\n",
    "              .format(accuracy_score(y_test, prediction)*100.))\n",
    "    print(\"\\n\")\n",
    "    print(\"----Classification report of the Logistic Regression classifier with default hyperparameter value----\")\n",
    "    print(\"\\n\")\n",
    "    print(classification_report(y_test, prediction, target_names=[\"Phishing Websites\", \"Normal Websites\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/phishing-websites-detection\" target=\"_blank\">https://app.wandb.ai/sayakpaul/phishing-websites-detection</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/phishing-websites-detection/runs/qwsql0cp\" target=\"_blank\">https://app.wandb.ai/sayakpaul/phishing-websites-detection/runs/qwsql0cp</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Logistic Regression classifier with default hyperparameter values 92.46%\n",
      "\n",
      "\n",
      "----Classification report of the Logistic Regression classifier with default hyperparameter value----\n",
      "\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Phishing Websites       0.93      0.90      0.91      3924\n",
      "  Normal Websites       0.92      0.94      0.93      4920\n",
      "\n",
      "        micro avg       0.92      0.92      0.92      8844\n",
      "        macro avg       0.92      0.92      0.92      8844\n",
      "     weighted avg       0.92      0.92      0.92      8844\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "train_eval_pipeline(logreg, (X_train, y_train),\n",
    "                         (X_test, y_test), \"logistic_regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we improve this model? A good way to start approaching is to tune the hyperparameters of the model. Let's first define a grid of values for the hyperparameters we would like to tune. We will using *random search* for hyperparameter tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid of values\n",
    "penalty = [\"l1\", \"l2\"]\n",
    "C = [0.8, 0.9, 1.0]\n",
    "tol = [0.01, 0.001 ,0.0001]\n",
    "max_iter = [100, 150, 200, 250]\n",
    "\n",
    "# Create a dictionary where tol and max_iter are keys and the lists \n",
    "# of their values are the corresponding values\n",
    "param_grid = dict(penalty=penalty, C=C, tol=tol, max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined the grid, let's use it to find a good set of hyperparameter values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 92.44 using {'tol': 0.0001, 'penalty': 'l1', 'max_iter': 100, 'C': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate RandomizedSearchCV with the required parameters\n",
    "random_model = RandomizedSearchCV(estimator=logreg, param_distributions=param_grid, cv=5)\n",
    "\n",
    "# Fit random_model to the data\n",
    "random_model_result = random_model.fit(X_train, y_train)\n",
    "\n",
    "# Summarize results\n",
    "best_score, best_params = random_model_result.best_score_, random_model_result.best_params_\n",
    "print(\"Best score: %.2f using %s\" % (best_score*100., best_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random search did not help much in boosting up the accuracy score. Just to ensure let's take the hyperparameter values and train another Logistic Regression model with those. \n",
    "\n",
    "As an additional exercise, you might want to define a distribution instead of specifying a grid of values and let the random search algorithm randomly sample values from that distribution and see the results. Follow [this article](https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/) to know more about this process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first log the hyperparameter values with which we are going to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    }
   ],
   "source": [
    "config = wandb.config\n",
    "\n",
    "config.tol = 0.001\n",
    "config.penalty = \"l1\"\n",
    "config.C = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/sayakpaul/phishing-websites-detection\" target=\"_blank\">https://app.wandb.ai/sayakpaul/phishing-websites-detection</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/sayakpaul/phishing-websites-detection/runs/ifb81mzh\" target=\"_blank\">https://app.wandb.ai/sayakpaul/phishing-websites-detection/runs/ifb81mzh</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.19 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Logistic Regression classifier with default hyperparameter values 92.48%\n",
      "\n",
      "\n",
      "----Classification report of the Logistic Regression classifier with default hyperparameter value----\n",
      "\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Phishing Websites       0.93      0.90      0.91      3924\n",
      "  Normal Websites       0.92      0.94      0.93      4920\n",
      "\n",
      "        micro avg       0.92      0.92      0.92      8844\n",
      "        macro avg       0.93      0.92      0.92      8844\n",
      "     weighted avg       0.92      0.92      0.92      8844\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "logreg = LogisticRegression(tol=config.tol, penalty=config.penalty, max_iter=250, C=config.C)\n",
    "train_eval_pipeline(logreg, (X_train, y_train),\n",
    "                         (X_test, y_test), \"logistic-regression-random-search\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
